{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Author: Ruben Schild<br>\n",
    "Student number: 650580<br>\n",
    "Date: 21-5-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook to work you must have installed the following packages (usually via pip install *packageName*:\n",
    "* numpy\n",
    "* pandas\n",
    "* matplot\n",
    "* seaborn\n",
    "* statsmodels\n",
    "* sklearn\n",
    "* eli5\n",
    "* xgboost\n",
    "* svm (from sklearn) <br>\n",
    "From these we will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas already installed, only imported\n",
      "NumPy already installed, only imported\n",
      "PyPlot already installed, only imported\n",
      "seaborn already installed, only imported\n",
      "statsmodels already installed, only imported\n",
      "sklearn already installed, only imported\n",
      "eli5 already installed, only imported\n",
      "svm installed\n",
      "xgboost installed\n"
     ]
    }
   ],
   "source": [
    "# pandas as pd\n",
    "try:\n",
    "    import pandas as pd\n",
    "    print('Pandas already installed, only imported')\n",
    "except:\n",
    "    !pip install pandas\n",
    "    import pandas as pd\n",
    "    print('Pandas was not installed, installed and imported')\n",
    "    \n",
    "# numpy as np\n",
    "try:\n",
    "    import numpy as np\n",
    "    print('NumPy already installed, only imported')\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np\n",
    "    print('NumPy was not installed, installed and imported')\n",
    "    \n",
    "# pyplot as plt\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print('PyPlot already installed, only imported')\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    print('PyPlot was not installed, installed and imported')    \n",
    "\n",
    "# sns\n",
    "\n",
    "try: \n",
    "    import seaborn as sns\n",
    "    print('seaborn already installed, only imported')\n",
    "except:\n",
    "    !pip install seaborn\n",
    "    print('seaborn was not installed, installed and imported')\n",
    "\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    print('statsmodels already installed, only imported')\n",
    "\n",
    "except:\n",
    "    !pip install statsmodels\n",
    "    print('statsmodels was not installed, installed and imported')\n",
    "\n",
    "# sklearn\n",
    "try:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    print('sklearn already installed, only imported')\n",
    "except:\n",
    "    !pip install sklearn\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    print('sklearn was not installed, installed and imported')\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "try:\n",
    "    import eli5\n",
    "    print('eli5 already installed, only imported')\n",
    "except:\n",
    "    !pip install eli5\n",
    "    import eli5\n",
    "    print('eli5 was not installed, installed and imported')\n",
    "\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "try:\n",
    "    import sklearn.svm\n",
    "    print('svm installed')\n",
    "except:\n",
    "    print('not installed')\n",
    "\n",
    "try:\n",
    "    import xgboost\n",
    "    print('xgboost installed')\n",
    "except:\n",
    "    print('not installed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Data\n",
    "We are going to use the datafile from a customers personality analysis. The collected data is the buying behaviour of customers at a grocery store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the code to load the data\n",
    "loan_df = pd.read_csv('../data/loan.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if there are missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan ID                           514\n",
       "Customer ID                       514\n",
       "Loan Status                       514\n",
       "Current Loan Amount               514\n",
       "Term                              514\n",
       "Credit Score                    19668\n",
       "Annual Income                   19668\n",
       "Years in current job             4736\n",
       "Home Ownership                    514\n",
       "Purpose                           514\n",
       "Monthly Debt                      514\n",
       "Years of Credit History           514\n",
       "Months since last delinquent    53655\n",
       "Number of Open Accounts           514\n",
       "Number of Credit Problems         514\n",
       "Current Credit Balance            514\n",
       "Maximum Open Credit               516\n",
       "Bankruptcies                      718\n",
       "Tax Liens                         524\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are some some missing values, so lets remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan ID                         0\n",
       "Customer ID                     0\n",
       "Loan Status                     0\n",
       "Current Loan Amount             0\n",
       "Term                            0\n",
       "Credit Score                    0\n",
       "Annual Income                   0\n",
       "Years in current job            0\n",
       "Home Ownership                  0\n",
       "Purpose                         0\n",
       "Monthly Debt                    0\n",
       "Years of Credit History         0\n",
       "Months since last delinquent    0\n",
       "Number of Open Accounts         0\n",
       "Number of Credit Problems       0\n",
       "Current Credit Balance          0\n",
       "Maximum Open Credit             0\n",
       "Bankruptcies                    0\n",
       "Tax Liens                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.dropna(inplace=True)\n",
    "loan_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan ID</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Loan Status</th>\n",
       "      <th>Current Loan Amount</th>\n",
       "      <th>Term</th>\n",
       "      <th>Credit Score</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Years in current job</th>\n",
       "      <th>Home Ownership</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Monthly Debt</th>\n",
       "      <th>Years of Credit History</th>\n",
       "      <th>Months since last delinquent</th>\n",
       "      <th>Number of Open Accounts</th>\n",
       "      <th>Number of Credit Problems</th>\n",
       "      <th>Current Credit Balance</th>\n",
       "      <th>Maximum Open Credit</th>\n",
       "      <th>Bankruptcies</th>\n",
       "      <th>Tax Liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4eed4e6a-aa2f-4c91-8651-ce984ee8fb26</td>\n",
       "      <td>5efb2b2b-bf11-4dfd-a572-3761a2694725</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2231892.0</td>\n",
       "      <td>8 years</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>29200.53</td>\n",
       "      <td>14.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>297996.0</td>\n",
       "      <td>750090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>273581de-85d8-4332-81a5-19b04ce68666</td>\n",
       "      <td>90a75dde-34d5-419c-90dc-1e58b04b3e35</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>217646.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>730.0</td>\n",
       "      <td>1184194.0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>Home Mortgage</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>10855.08</td>\n",
       "      <td>19.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122170.0</td>\n",
       "      <td>272052.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8af915d9-9e91-44a0-b5a2-564a45c12089</td>\n",
       "      <td>af534dea-d27e-4fd6-9de8-efaa52a78ec0</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>548746.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>678.0</td>\n",
       "      <td>2559110.0</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>18660.28</td>\n",
       "      <td>22.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>437171.0</td>\n",
       "      <td>555038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32c2e48f-1ba8-45e0-a530-9a6622c18d9c</td>\n",
       "      <td>0de7bcdb-ebf4-4608-ba39-05f083f855b6</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>728.0</td>\n",
       "      <td>714628.0</td>\n",
       "      <td>3 years</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>11851.06</td>\n",
       "      <td>16.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203965.0</td>\n",
       "      <td>289784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>403d7235-0284-4bb6-919a-09402fecbf7b</td>\n",
       "      <td>11581f68-de3c-49d8-80d9-22268ebb323b</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>99999999.0</td>\n",
       "      <td>Short Term</td>\n",
       "      <td>740.0</td>\n",
       "      <td>776188.0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>Own Home</td>\n",
       "      <td>Debt Consolidation</td>\n",
       "      <td>11578.22</td>\n",
       "      <td>8.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134083.0</td>\n",
       "      <td>220220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Loan ID  \\\n",
       "2   4eed4e6a-aa2f-4c91-8651-ce984ee8fb26   \n",
       "6   273581de-85d8-4332-81a5-19b04ce68666   \n",
       "8   8af915d9-9e91-44a0-b5a2-564a45c12089   \n",
       "10  32c2e48f-1ba8-45e0-a530-9a6622c18d9c   \n",
       "12  403d7235-0284-4bb6-919a-09402fecbf7b   \n",
       "\n",
       "                             Customer ID Loan Status  Current Loan Amount  \\\n",
       "2   5efb2b2b-bf11-4dfd-a572-3761a2694725  Fully Paid           99999999.0   \n",
       "6   90a75dde-34d5-419c-90dc-1e58b04b3e35  Fully Paid             217646.0   \n",
       "8   af534dea-d27e-4fd6-9de8-efaa52a78ec0  Fully Paid             548746.0   \n",
       "10  0de7bcdb-ebf4-4608-ba39-05f083f855b6  Fully Paid           99999999.0   \n",
       "12  11581f68-de3c-49d8-80d9-22268ebb323b  Fully Paid           99999999.0   \n",
       "\n",
       "          Term  Credit Score  Annual Income Years in current job  \\\n",
       "2   Short Term         741.0      2231892.0              8 years   \n",
       "6   Short Term         730.0      1184194.0             < 1 year   \n",
       "8   Short Term         678.0      2559110.0              2 years   \n",
       "10  Short Term         728.0       714628.0              3 years   \n",
       "12  Short Term         740.0       776188.0             < 1 year   \n",
       "\n",
       "   Home Ownership             Purpose  Monthly Debt  Years of Credit History  \\\n",
       "2        Own Home  Debt Consolidation      29200.53                     14.9   \n",
       "6   Home Mortgage  Debt Consolidation      10855.08                     19.6   \n",
       "8            Rent  Debt Consolidation      18660.28                     22.6   \n",
       "10           Rent  Debt Consolidation      11851.06                     16.0   \n",
       "12       Own Home  Debt Consolidation      11578.22                      8.5   \n",
       "\n",
       "    Months since last delinquent  Number of Open Accounts  \\\n",
       "2                           29.0                     18.0   \n",
       "6                           10.0                     13.0   \n",
       "8                           33.0                      4.0   \n",
       "10                          76.0                     16.0   \n",
       "12                          25.0                      6.0   \n",
       "\n",
       "    Number of Credit Problems  Current Credit Balance  Maximum Open Credit  \\\n",
       "2                         1.0                297996.0             750090.0   \n",
       "6                         1.0                122170.0             272052.0   \n",
       "8                         0.0                437171.0             555038.0   \n",
       "10                        0.0                203965.0             289784.0   \n",
       "12                        0.0                134083.0             220220.0   \n",
       "\n",
       "    Bankruptcies  Tax Liens  \n",
       "2            0.0        0.0  \n",
       "6            1.0        0.0  \n",
       "8            0.0        0.0  \n",
       "10           0.0        0.0  \n",
       "12           0.0        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter the code to see the first few rows of the data\n",
    "loan_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fully Paid', 'Charged Off'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to see the types of loan statuses\n",
    "loan_df['Loan Status'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span>\\<explain the variables (/fields/columns) you are going to use for your prediction. The dependent y (the one you are going to predict) and two independent x's (the ones you are going to use to predict that y). What do these variables mean?\\></span>**\n",
    "\n",
    "We are going to predict the status of a loan based on the anual income and the monthly debt the borrower has. <br>\n",
    "These independent variables should be interesting on the outcome of the loan status. A high annual income would probably mean you can fully pay off the loan whereas a low anual income it would be more difficult. <br>\n",
    "The same goes for monthly debt, but then the other way around; if the borrower has a higher debt per month, the chance of the loan being charged off could be higher than when there is a lower monthly debt. \n",
    "\n",
    "*note:* Its easiest if your independent x variables are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a separate datafram based on the selected variables\n",
    "loan_ss = loan_df[['Loan Status', 'Annual Income', 'Monthly Debt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan Status      0\n",
       "Annual Income    0\n",
       "Monthly Debt     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_ss.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical dependent variable loan status has the following categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruben\\AppData\\Local\\Temp\\ipykernel_18184\\4021867281.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  loan_ss['Loan Status'] = pd.Categorical(loan_ss['Loan Status'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Charged Off', 'Fully Paid'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code that returns the different categories in the y variable.\n",
    "loan_ss['Loan Status'] = pd.Categorical(loan_ss['Loan Status'])\n",
    "loan_ss['Loan Status'].cat.categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need some training and testing data, so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to split data in training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set input and output\n",
    "X = loan_ss[['Annual Income', 'Monthly Debt']]\n",
    "y = loan_ss['Loan Status']\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All set, lets try to predict this using our independent variable Annual Income and Monthly Debt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Basic Classification Models\n",
    "\n",
    "In the Jupyter Notebook from lecture 5 a few different Classification techniques were discussed. Lets explore how these perform on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at some 'real' models, its a good idea to get a baseline in by using one or more of the dummy classifiers. Lets see how they perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7964310226492793\n",
      "[[   0 1483]\n",
      " [   0 5802]]\n"
     ]
    }
   ],
   "source": [
    "# code to create, fit and measure the dummy classifiers (see chapter 5.4. in the lecture notebook)\n",
    "# include both the accuracy score and the confusion matrix for each.\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Dummy classifier with stratified method\n",
    "dumSrat = DummyClassifier(strategy=\"most_frequent\")\n",
    "drumSrat = dumSrat.fit(X_train, y_train)\n",
    "y_pred_most = dumSrat.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred_most))\n",
    "print(confusion_matrix(y_test, y_pred_most))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<explain all the results. What do the numbers mean?></span>**\n",
    "\n",
    "So the first dummy model performed okay, with a rounded up score of 80% with the testing data. <br>\n",
    "The confusion matrix of the model predicted 0 times the annual income and it actually was 0 times. It predicted 5802 the monthly debt and it was the monthly debt 5802 times. 1483 it predicted montly debt but was annual income. And 1187 times it predicted annual income but it actually was 1187 times monthly debt.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, those are our 'baseline'. A model should be able to at least outperform these.\n",
    "\n",
    "Lets dive in..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Naive Bayes\n",
    "\n",
    "The first model discussed was the Naive Bayes model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\<explain briefly in your own words how a Naive Bayes method works>** <br>\n",
    "The Naive Bayes theorem assumes that there is independence among the other predictors. With this theorem you can calculate $P(A|B)$ if B is known, given A. So $P(B|A)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create and fit this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create the model, and fit the data.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Because we use numerical input, we need the Gaussian Distribution\n",
    "gaussNB = GaussianNB()\n",
    "\n",
    "# Make the model and create a prediction\n",
    "gaussNB.fit(X_train, y_train)\n",
    "y_predG = gaussNB.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to measure its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7964310226492793\n",
      "[[   0 1483]\n",
      " [   0 5802]]\n"
     ]
    }
   ],
   "source": [
    "# code to show its accuracy score AND confusion matrix.\n",
    "print(metrics.accuracy_score(y_test, y_predG))\n",
    "print(confusion_matrix(y_test, y_predG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<explain all the results. What do the numbers mean? How is this compared to the dummy classifiers?></span>** <br>\n",
    "The Gaussian model performed quite good with a rounded up score of 80% with the testing data. The confusion matrix of Gaussian model predicted 0 times the annual income and it was 0 times. It predicted 5802 the monthly debt and it was the monthly debt. 1483 it predicted montly debt but was annual income. And 0 times it predicted annual income and it was 0 times annual income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely, the Gaussian model performed exactly the same as the 2 dummy models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also have a look at what a prediction would be. If the Annual Income has a score of 85% and the Monthly Debt has a score of 80%, then this model will predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fully Paid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# code to show the prediction\n",
    "test = [0.85, 0.8]\n",
    "test = np.array(test)\n",
    "test = test.reshape(1, -1)\n",
    "print(gaussNB.predict(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about it for NB. A nice thing about NB is that it doesn't really require any parameters. Lets look at our next technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Support Vector Machines\n",
    "The second model discussed were Support Vector Machines. There is a plural here, because we can use different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style =''>\\<explain briefly in your own words how a SVM method works></span>** <br>\n",
    "\n",
    "A SVM method basically works by converting data to a point that data points can be categorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic kernel is the linear one, so we'll attempt that first:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note  <br>\n",
    "The SVM methods all took too much time to compile (300 min and no results), because my dataset is too big I think. <br> \n",
    "So instead of the regular data, we are going to scale the test and train variables already, so we can use the normal dataset (unchanged and not shortend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data because the normal data took too much time to run\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# set the scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Convert the train and test X values, using the same scaler (so based on the X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model, then fit the model, and determine the predicted values with the scaled values\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svmLin_normal = SVC(kernel='linear')\n",
    "svmLin_normal.fit(X_train_scaled, y_train)\n",
    "y_pred_normal = svmLin_normal.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring its performance...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.7964310226492793\n",
      "[[   0 1483]\n",
      " [   0 5802]]\n"
     ]
    }
   ],
   "source": [
    "# code to show its accuracy score AND confusion matrix. with the scaled values\n",
    "print('accuracy score: ', metrics.accuracy_score(y_test, y_pred_normal))\n",
    "print(confusion_matrix(y_test, y_pred_normal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style >\\<explain all the results. What do the numbers mean? How is this compared to the dummy classifiers, and the NB?></span>** <br>\n",
    "\n",
    "The SVM Linear model took too long with the regular data, so I scaled the variables already, like I mentioned before. <br>\n",
    "The linear model performed quite good with a score of 80% rounded up with the testing data, strangly enough, the results are exactly the same as the Gaussian model and the dummy model. <br>\n",
    "The confusion matrix of the Linear model predicted 0 times the annual income and it was 0 times. It predicted 5802 the monthly debt and it was the monthly debt. 1483 it predicted montly debt but was annual income. And 0 times it predicted annual income and it was 0 times annual income. Just like the other models before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the same for the other kernels that were discussed, i.e. rbf, polynomial, and sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "For these models I am also going to the scaled variables, because they also took too much time running. <br>\n",
    "For the polynomial and sigmoid kernel, I am going to use a medium sized since my running time was over 30 min long with no results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan Status</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Monthly Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>2231892.0</td>\n",
       "      <td>29200.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>1184194.0</td>\n",
       "      <td>10855.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>2559110.0</td>\n",
       "      <td>18660.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>714628.0</td>\n",
       "      <td>11851.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>776188.0</td>\n",
       "      <td>11578.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loan Status  Annual Income  Monthly Debt\n",
       "2   Fully Paid      2231892.0      29200.53\n",
       "6   Fully Paid      1184194.0      10855.08\n",
       "8   Fully Paid      2559110.0      18660.28\n",
       "10  Fully Paid       714628.0      11851.06\n",
       "12  Fully Paid       776188.0      11578.22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select first 4869 rows\n",
    "medium_loan_ss = loan_ss[0:4869]\n",
    "medium_loan_ss.dropna()\n",
    "medium_loan_ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_medium = medium_loan_ss[['Annual Income', 'Monthly Debt']]\n",
    "y_medium = medium_loan_ss['Loan Status']\n",
    "\n",
    "#Split the data\n",
    "X_train_medium, X_test_medium, y_train_medium, y_test_medium = train_test_split(X_medium, y_medium, test_size=0.2,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF Kernel results\n",
      "accuracy score:  0.7964310226492793\n",
      "[[   0 1483]\n",
      " [   0 5802]]\n",
      "\n",
      "SVM poly Kernel results\n",
      "accuracy score:  0.7967145790554415\n",
      "[[  0 198]\n",
      " [  0 776]]\n",
      "\n",
      "SVM sigmoid Kernel results\n",
      "accuracy score:  0.648870636550308\n",
      "[[ 31 167]\n",
      " [175 601]]\n"
     ]
    }
   ],
   "source": [
    "# code to create the models, fit the data, and show its accuracy score AND confusion matrix.\n",
    "# make sure to print some text between to indicate which result belongs to which model.\n",
    "\n",
    "# This cell took about roughly 2 minutes on my laptop to load.\n",
    "\n",
    "# SVM with Radial Basis Function kernel\n",
    "rbfKer = SVC(kernel='rbf')\n",
    "rbfKer.fit(X_train_scaled, y_train)\n",
    "y_pred_rbf = rbfKer.predict(X_test_scaled)\n",
    "\n",
    "print('SVM RBF Kernel results')\n",
    "print('accuracy score: ', metrics.accuracy_score(y_test, y_pred_rbf))\n",
    "print(confusion_matrix(y_test, y_pred_rbf))\n",
    "\n",
    "print()\n",
    "\n",
    "# SVM with Polynomial kernel\n",
    "svmPol = SVC(kernel='poly')\n",
    "svmPol.fit(X_train_medium, y_train_medium)\n",
    "y_pred_poly = svmPol.predict(X_test_medium)\n",
    "\n",
    "print('SVM poly Kernel results')\n",
    "print('accuracy score: ', metrics.accuracy_score(y_test_medium, y_pred_poly))\n",
    "print(confusion_matrix(y_test_medium, y_pred_poly))\n",
    "\n",
    "print()\n",
    "\n",
    "# SVM with Sigmoid Kernel\n",
    "svmSigm = SVC(kernel='sigmoid')\n",
    "svmSigm.fit(X_train_medium, y_train_medium)\n",
    "y_pred_sig = svmSigm.predict(X_test_medium)\n",
    "\n",
    "print('SVM sigmoid Kernel results')\n",
    "print('accuracy score: ', metrics.accuracy_score(y_test_medium, y_pred_sig))\n",
    "print(confusion_matrix(y_test_medium, y_pred_sig))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<explain all the results. What do the numbers mean? How is this compared to the dummy classifiers?></span>** <br>\n",
    "<br><br>\n",
    "The RDF model performed quite good with a rounded up score of 80% with the testing data also the same as the dummy, gaussian and Linear models. <br>\n",
    "The confusion matrix of RBF model predicted 0 times the annual income and it was 0 times. It predicted 5802 the monthly debt and it was the monthly debt. 1483 times it predicted montly debt but was annual income. And 0 times it predicted annual income and it was 0 times annual income.<br> <br>\n",
    "\n",
    "The Polynomial and the Sigmoid model both used a medium sized subset of the dataset<br><br>\n",
    "\n",
    "the polynomial kernel performed with a score of 80% rounded, the actual percentage was slightly higher than the RBF kernel. <br>\n",
    "It predicted 0 times the annual income and that was right. It predicted 776 times the Monthly debt which was right. And it predicted 198 times the Monthly debt but was Annual Income. It predicted 0 times monthly debt, which is also right.\n",
    "\n",
    "the sigmoid model performed worse than the above mentioned and the dummy and gaussian models, with a score of 65% rounded up. <br>\n",
    "\n",
    "It predicted 31 times annual income right. Also it predicted 601 times monthly debt right. <br> 167 times it predicted monthly debt but was annual income, and 175 times it predicted annual income but was monthly debt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RBF model performed the same as the dummy, gaussian and linear SVM. The Polynomial kernel performed just slightly better than the ones before. <br>\n",
    "The Sigmoid model performed worse than the dummy, gaussian, polynomial and RDF models. <br>\n",
    "\n",
    "(Please notice that the dataset for the polynomial and sigmoid predictions are with the medium dataset because of the duration of excecution)\n",
    "\n",
    "## not yet done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allright, lets move on to the third technique..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. K-Nearest Neighbors\n",
    "The third technique is the K-Nearest Neighbors (KNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<explain briefly in your own words how a KNN method works></span>** <br>\n",
    "\n",
    "A datapoint will be classified as X, with the condition that the majority of the 'nearest neighbors' is X, otherwise it will be classified as Y or something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this we need to do some additional steps.\n",
    "\n",
    "First we need to normalize our x variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the StandardScaler to normalize the two x variables\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# set the scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Convert the train and test X values, using the same scaler (so based on the X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second we need to determine how many neighbors (k) we want. To do this we'll visualize the results using different values for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "for i in range(1, 80):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    pred_i = knn.predict(X_test_scaled)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code to create the graph with Error Rate vs. K-values.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 80), error_rate, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<explain the result and your choice for k based on the graph></span>** <br>\n",
    "I am thinking to take 21, because from there on the error rate seems to stay constant. But first I want to see what the grid search will find with the medium dataset.\n",
    "\n",
    "*Note:* +0.5 if you also use the GridSearch technique to decide on k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "For the extra point I am going to try and find the best k with the medium sized dataset. <br>\n",
    "So we need to scale the variables first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_medium = scaler.transform(X_train_medium)\n",
    "X_test_scaled_medium = scaler.transform(X_test_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 1\n",
      "Best p: 1\n",
      "Best n_neighbors: 29\n"
     ]
    }
   ],
   "source": [
    "# Code to find best neighbor\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "#Create new KNN object\n",
    "knn_2 = KNeighborsClassifier()\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train_scaled_medium, y_train_medium)\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what we want k to be, we can create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create the model with the selected k\n",
    "knn = KNeighborsClassifier(n_neighbors = 29)\n",
    "\n",
    "knn.fit(X_train_scaled_medium, y_train_medium)\n",
    "y_pred_knn = knn.predict(X_test_scaled_medium)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out how good it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7967145790554415\n",
      "[[  0 198]\n",
      " [  0 776]]\n"
     ]
    }
   ],
   "source": [
    "# code to show its accuracy score AND confusion matrix.\n",
    "print(metrics.accuracy_score(y_test_medium, y_pred_knn))\n",
    "print(confusion_matrix(y_test_medium, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<explain all the results. What do the numbers mean? How is this compared to the dummy classifiers, the NB, and the SVM kernels?></span>** <br> <br>\n",
    "\n",
    "First I wanted to take 21 as the K value, but according to the grid search, 29 seemed to be the best K for the medium sized dataset. <br><br>\n",
    "\n",
    "The K value is the number of nearest neighbors that should be used to classify the datapoint. In our case, 29 neighbors seemed to be the best number. <br><br>\n",
    "\n",
    "The KNN performed exactly the same as the Polynomial model. And it out performed the dummy, gaussian, RDF and sigmoid models. <br><br>\n",
    "\n",
    "The score of the KNN was 80% rounded up and exactly the same as the polynomial kernal.<br>\n",
    "It predicted 0 times the annual income and that was right. It predicted 776 times the Monthly debt which was right. And it predicted 198 times the Monthly debt but was Annual Income. It predicted 0 times monthly debt, which is also right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more basic technique to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Decision Trees\n",
    "The last technique that was discussed in detail, were the Decision Trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<explain briefly in your own words how a Decision Tree method works></span>** <br><br>\n",
    "\n",
    "A decision tree works by splitting up the population of data points into smaller segments, and based on some condition the segment gets classified a certain class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following variations were discussed:\n",
    "\n",
    "* ID3 (or entropy with sklearn)\n",
    "* Gini\n",
    "* Random Forest\n",
    "* Extra trees\n",
    "\n",
    "Hopefully we have the hang of this now, so lets do each of them in one go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy\n",
      "0.7283459162663006\n",
      "[[ 368 1115]\n",
      " [ 864 4938]]\n",
      "\n",
      "gini\n",
      "0.7250514756348662\n",
      "[[ 356 1127]\n",
      " [ 876 4926]]\n",
      "\n",
      "Random forest\n",
      "0.7714481811942348\n",
      "[[ 138 1345]\n",
      " [ 320 5482]]\n",
      "\n",
      "Extra trees\n",
      "0.7640356897735072\n",
      "[[ 173 1310]\n",
      " [ 409 5393]]\n"
     ]
    }
   ],
   "source": [
    "# code to create the models, fit the data, and show its accuracy score AND confusion matrix.\n",
    "# make sure to print some text between to indicate which result belongs to which model.\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "ent_dtc = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "ent_dtc.fit(X_train_scaled,y_train)\n",
    "y_pred = ent_dtc.predict(X_test_scaled)\n",
    "print('Entropy')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "gini_dtc = DecisionTreeClassifier(criterion = \"gini\")\n",
    "gini_dtc.fit(X_train_scaled,y_train)\n",
    "y_pred = gini_dtc.predict(X_test_scaled)\n",
    "print('gini')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfcModel = rfc.fit(X_train_scaled, y_train)\n",
    "y_pred = rfcModel.predict(X_test_scaled)\n",
    "print('Random forest')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "erfc = ExtraTreesClassifier(random_state=0)\n",
    "erfc = erfc.fit(X_train_scaled, y_train)\n",
    "y_pred = erfc.predict(X_test_scaled)\n",
    "print('Extra trees')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<explain all the results. What do the numbers mean? How is this compared to the dummy classifiers, the NB, the SVM kernels, and the knn?></span>** <br><br>\n",
    "\n",
    "Entropy <br>\n",
    "Entropy performed a score of 73% rounded up. <br>\n",
    "368 times it predicted annual income and that was true. 4938 times it predicted Monthly debt and that was also right. <br>\n",
    "1115 times it predicted Monthly Debt but was annual income. And it predicted 864 times Annual income, but was Monthly Debt <br><br>\n",
    "\n",
    "Gini <br>\n",
    "gini performed a score of 77%. <br>\n",
    "356 times it predicted annual income and that was true. 4926 times it predicted Monthly debt and that was also right. <br>\n",
    "1127 times it predicted Monthly Debt but was annual income. And it predicted 876 times Annual income, but was Monthly Debt <br><br>\n",
    "\n",
    "Random forest <br>\n",
    "Random forst performed a score of 77%. <br>\n",
    "138 times it predicted annual income and that was true. 5482 times it predicted Monthly debt and that was also right. <br>\n",
    "1345 times it predicted Monthly Debt but was annual income. And it predicted 320 times Annual income, but was Monthly Debt <br><br>\n",
    "\n",
    "Extra trees <br>\n",
    "Extra trees performed a score of 76%. <br>\n",
    "173 times it predicted annual income and that was true. 5393 times it predicted Monthly debt and that was also right. <br>\n",
    "1310 times it predicted Monthly Debt but was annual income. And it predicted 409 times Annual income, but was Monthly Debt <br><br>\n",
    "\n",
    "These models performed slightly worse than the Dummy, Gaussian, Linear SVM, RBF, Polynomial and KNN models. But Performed better than the Sigmoid model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last set of techniques to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Other Models\n",
    "In the Jupyter Notebook from the lecture, in chapter 5.4 a few more techniques were simply shown:\n",
    "\n",
    "* Linear Discriminant Analysis\n",
    "* Quadratic Discriminant Analysis\n",
    "* Logistic Regression Classifier\n",
    "* Multinomial Logistic Regression Classification\n",
    "* Adaptive Boosting\n",
    "* Gradient Boosting\n",
    "* Histogram Gradient Boosting\n",
    "* XGBoost\n",
    "* Stacking\n",
    "\n",
    "Out of curiousity lets see how these perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear discriminant\n",
      "0.7964310226492793\n",
      "\n",
      "quadratic discriminant\n",
      "0.7964310226492793\n",
      "\n",
      "logistic regression\n",
      "0.7964310226492793\n",
      "\n",
      "multinomial logistic regression\n",
      "0.7964310226492793\n",
      "\n",
      "Adaptive boost\n",
      "0.7962937542896362\n",
      "\n",
      "Gradient boost\n",
      "0.7964310226492793\n",
      "\n",
      "histogram gradient boost\n",
      "0.7964310226492793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking\n",
      "0.7964310226492793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# code to create the models, fit the data, and show its accuracy score (the confusion matrix is here optional).\n",
    "# make sure to print some text between to indicate which result belongs to which model.\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "ldaModel=lda.fit(X_train_scaled, y_train)\n",
    "y_pred=ldaModel.predict(X_test_scaled)\n",
    "print('linear discriminant')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qdaModel=qda.fit(X_train_scaled, y_train)\n",
    "y_pred=ldaModel.predict(X_test_scaled)\n",
    "print('quadratic discriminant')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "lrModel = logreg.fit(X_train_scaled, y_train)\n",
    "y_pred = lrModel.predict(X_test_scaled)\n",
    "print('logistic regression')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(multi_class='multinomial')\n",
    "lrModel = logreg.fit(X_train_scaled, y_train)\n",
    "y_pred = lrModel.predict(X_test_scaled)\n",
    "print('multinomial logistic regression')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "adaBst = AdaBoostClassifier(random_state=0)\n",
    "adaBst = adaBst.fit(X_train_scaled, y_train)\n",
    "y_pred = adaBst.predict(X_test_scaled)\n",
    "print('Adaptive boost')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "gradBst = GradientBoostingClassifier(random_state=0)\n",
    "gradBst = gradBst.fit(X_train_scaled, y_train)\n",
    "y_pred = gradBst.predict(X_test_scaled)\n",
    "print('Gradient boost')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "histBst = HistGradientBoostingClassifier(random_state=0)\n",
    "histBst = histBst.fit(X_train_scaled, y_train)\n",
    "y_pred = histBst.predict(X_test_scaled)\n",
    "print('histogram gradient boost')\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('svr', make_pipeline(StandardScaler(),\n",
    "                          LinearSVC(random_state=42)))]\n",
    "\n",
    "stackCl = StackingClassifier(estimators=estimators, final_estimator = LogisticRegression())\n",
    "stackCl.fit(X_train_scaled, y_train)\n",
    "y_pred = stackCl.predict(X_test_scaled)\n",
    "print('stacking')\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ruben\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.73%\n"
     ]
    }
   ],
   "source": [
    "# multiclass classification\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load data\n",
    "loan_df = pd.read_csv('../data/loan.csv')\n",
    "loan_df = loan_df[['Loan Status', 'Annual Income', 'Monthly Debt']].dropna()\n",
    "\n",
    "# split data into X and y\n",
    "X = loan_df[['Annual Income', 'Monthly Debt']]\n",
    "Y = loan_df[['Loan Status']]\n",
    "\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span >\\<which performed best?></span>**<br>\n",
    "\n",
    "stacking, histogram gradient boost, Gradient boost, multinomial logistic regression, logistic regression, quadratic discriminant and the linear discriminant scored the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"><center>-----Chapters 1 and 2 are required to be fully completed to get a 60, the next few chapters will give a +10 for each chapter.<br> \n",
    "    However the template is not as extensive as the previous chapters. <br>\n",
    "    You can select any chapter below the order is not fixed (you can leave the others empty)<br>\n",
    "    You don't have to use the same dataset for the chapters below. If it helps in clarification you can use another dataset, but then make sure to include it as you submit.\n",
    "    ----</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualisation\n",
    "\n",
    "With two input parameters we can actually determine visually where a model will classify a variable into which category. An overview of such plots is shown at https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "We cannot copy that code since it does a comparison. What we want is a function that takes the X and Y data as input, as well as the model to be used and then shows the decision areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code for the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of using the function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Categorical Input\n",
    "With classification we have a categorical output variable, but what if we also have one or more categorical input variables.\n",
    "\n",
    "One popular technique is one-hot-encoding, but there are others.\n",
    "\n",
    "In this chapter we'll discuss **<span style ='background:yellow'>\\<your chosen technique></span>**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style ='background:yellow'>\\<explain the technique in detail. What does it do and how does it work></span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code of using this technique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Performance\n",
    "Some models get higher accuracy scores than others. In the Jupyter Notebook from the lecture the UFC data was used and the QDA had the highest accuracy score: 0.6747. The big question is, can it be done better? First areas to look for improvement are to simply increase the number of input variables, or tweak some parameters of some of the models, or a combination of both.\n",
    "\n",
    "In this chapter we'll give it an attempt.\n",
    "\n",
    "First we need to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to load the UFC data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style ='background:yellow'>\\<explain your attempt, what did you do.></span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that will generate an accuracy score for the outcome that is higher than 0.6747\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. A New Technique\n",
    "\n",
    "Many techniques were discussed in class and the lecture Jupyter Notebook, but there are a lot more. In this chapter the \\<your chosen new technique> is discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style ='background:yellow'>\\<explain in detail this new technique. Note that other students should be able to understand it from your explanation alone!></span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code on using this technique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style ='background:yellow'>\\<feel free to use more cells for this, you probably need them></span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0eb7650236ad649532561a0bb09336eae6a470ad46c281d5d8431873b9e5bf00"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
