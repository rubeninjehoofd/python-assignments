{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining and Statistics\n",
    "## Session 5 - Classification\n",
    "*Peter Stikker - Haarlem, the Netherlands - v1.1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy as np\n",
    "try:\n",
    "    import numpy as np\n",
    "    print('NumPy already installed, only imported')\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np\n",
    "    print('NumPy was not installed, installed and imported')\n",
    "      \n",
    "# pyplot as plt\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    print('PyPlot already installed, only imported')\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    print('PyPlot was not installed, installed and imported')\n",
    "\n",
    "# pandas as pd   \n",
    "try:\n",
    "    import pandas as pd\n",
    "    print('pandas already installed, only imported')\n",
    "except:\n",
    "    !pip install pandas\n",
    "    import pandas as pd\n",
    "    print('pandas was not installed, installed and imported')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is named after Bayes Theorem, which is:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(A|B) = \\frac{P(B|A)\\times P(A)}{P(B)}\n",
    "\\end{equation*}\n",
    "\n",
    "The $P(A|B)$ needs to be read as 'the probability of A, given that B has occured'. Bayes Theorem makes it possible to calculate this if we have the probability of B, given A ($P(B|A)$).\n",
    "\n",
    "On the slides we'll do a quick manual calculation, so lets focus here on applying the Naive Bayes.\n",
    "\n",
    "You might be wondering why it's called 'Naive'. Thats because it assumes that the indpendent variables do not depent on each other, which is termed 'naive'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1. Naive Bayes with Categorical Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most explanations on how Naive Bayes works, is done by using an example with Categorical data. Oddly enough most examples that show applications in Python, work with numerical data. Sklearn has not yet added an option for dealing with categorical data in their stable release, but there is luckily one in beta stage.\n",
    "\n",
    "We begin with loading in some example data. This was based on the data at https://medium.com/@prgopinath100/naive-bayes-classifier-dd8b179b5d90. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable name 'seldf' as in 'selection data frame'\n",
    "seldf=pd.read_csv('data/selection.csv', sep = ';', names=[\"experience\", \"form\", \"fitness\", \"selected\"])\n",
    "seldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the sklearn Naive Bayes option for Categorical input we unfortunately this will need to be re-coded into numerical values. We first let panda know which fields are 'Categorical':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldf[\"experience\"]=pd.Categorical(seldf[\"experience\"])\n",
    "seldf[\"form\"]=pd.Categorical(seldf[\"form\"])\n",
    "seldf[\"fitness\"]=pd.Categorical(seldf[\"fitness\"])\n",
    "seldf[\"selected\"]=pd.Categorical(seldf[\"selected\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each field the different categories can be obained using cat.code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldf[\"experience\"].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the numeric values of the field can be shown using .cat.codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldf[\"experience\"].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the numeric codes, so we build a numpy array using those codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable name 'selarr' was chosen, short for 'selection array'\n",
    "selarr = np.asarray(seldf[\"experience\"].cat.codes)\n",
    "selarr = np.dstack((selarr, np.asarray(seldf[\"form\"].cat.codes)))\n",
    "selarr = np.dstack((selarr, np.asarray(seldf[\"fitness\"].cat.codes)))\n",
    "selarr = np.dstack((selarr, np.asarray(seldf[\"selected\"].cat.codes)))\n",
    "selarr = np.squeeze(selarr)\n",
    "selarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can build our model.\n",
    "\n",
    "Define our predictors, and what we want to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=selarr[:,0:3]     ##the experience, form, and fitness\n",
    "y=selarr[:,3]       ##the selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the CategoricalNB from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how this performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catNB = CategoricalNB()\n",
    "catNB.fit(X, y)\n",
    "print(catNB.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these are the results of the analysis for the 'selected'. As a reminder we can find out what a 0 or 1 means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seldf[\"selected\"].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a 0 = no and 1 = yes. The earlier found [1 1 0 1 0 1 1 1 0 1 0 0] therefor indicates that the first and second person is predicted to be selected, the third isn't, the fourth is, etc.\n",
    "\n",
    "To see how well the model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catNB.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was correct is 64% of the cases. It was wrong for person 7, 8, 9 and 10, so correct in 7 out of 11 cases, which indeed equals 64%.\n",
    "\n",
    "And to actually see the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catNB.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first person is predicted to have a 44% chance of not being selected, and a 56% chance of being selected. Since 56 > 44, we'd predict this person to be selected.\n",
    "\n",
    "Lets do a prediction for someone whos experience = 1, form = 1 and Fitness = 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTest=[1,1,1]\n",
    "myTest=np.array(myTest)\n",
    "myTest = myTest.reshape(1, -1)\n",
    "print(catNB.predict(myTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted result is a 1, so a good chance to be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**\n",
    "\n",
    "Determine who is most likely to win in a match between a Southpaw fighter and a Orthodox player.\n",
    "\n",
    "Use the UFC2019.csv dataset and of course a naive Bayesian analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "# Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset of data and remove missing values\n",
    "\n",
    "\n",
    "# Convert panda fields to categorical\n",
    "\n",
    "\n",
    "# get the numerical values as a numpy array\n",
    "\n",
    "\n",
    "# set the independent (X) and dependent variable (Y)\n",
    "\n",
    "\n",
    "# Create and fit the model\n",
    "\n",
    "\n",
    "# Show some results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**\n",
    "\n",
    "Another example taken from: https://www.saedsayad.com/naive_bayesian.htm. The data is already available as 'playGolf.csv'. Load this data and create a model to predict if we can go Play or not.\n",
    "\n",
    "If you have time to spare, you could look into the conversion of the categories into the numerical ones by using the LabelEncoder option of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "\n",
    "# Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert panda fields to categorical\n",
    "\n",
    "# get the numerical values as a numpy array\n",
    "\n",
    "\n",
    "# set the independent (X) and dependent variable (Y)\n",
    "\n",
    "\n",
    "# Create and fit the model\n",
    "\n",
    "\n",
    "# Show some results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2. Naive Bayes with numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that we've seen how to create a Naive Bayes model, using categorical input variables. Lets go to the more commonly used version, with numerical data. \n",
    "\n",
    "With numerical data we usually cannot do a simple frequency count (many scores would have a frequency of 1 or just a few). For these it is often assumed they will follow a Normal Distribution, a.k.a. Gaussian Distribution. We won't go into the details of this and leave the calculations up to Python.\n",
    "\n",
    "First again some example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original UFC data\n",
    "UFCdata=pd.read_csv('data/UFC2019.csv',sep = ',', header=0)\n",
    "# store field names in separate list\n",
    "UFCfields=list(UFCdata.columns)\n",
    "\n",
    "#Convert numerical fields into own dataframe.\n",
    "UFCnum=pd.DataFrame()\n",
    "\n",
    "for i in UFCfields:\n",
    "    if (UFCdata[i].dtype=='int64' or UFCdata[i].dtype=='float64'):\n",
    "        UFCnum[i]=UFCdata[i]\n",
    "\n",
    "#Add the winner\n",
    "UFCnum['Winner']=UFCdata['Winner']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to make the model and look at the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Import the GaussianNB so we can use the commonly used Gaussian transformation\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Set our model to this GaussianNB\n",
    "gaussNB = GaussianNB()\n",
    "\n",
    "#Get the specific fields of interest\n",
    "mDat =UFCnum[[\"B_age\", \"R_age\", \"Winner\"]]\n",
    "# remove missing records and draws\n",
    "mDat=mDat.dropna()\n",
    "mDat = mDat[mDat.Winner != 'Draw']\n",
    "\n",
    "# Set input and output\n",
    "X = mDat[[\"B_age\", \"R_age\"]]\n",
    "y = mDat[\"Winner\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109)\n",
    "\n",
    "\n",
    "#Create the model and prediction\n",
    "gaussNB.fit(X_train, y_train)\n",
    "y_pred = gaussNB.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model had 66% correct in the testing data.\n",
    "\n",
    "We can have a more detailed look, by looking at the so-called confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top left value of 19, indicates that our model predicted a blue and it actually also was a blue 19 times.\n",
    "\n",
    "The bottom right value of 626 indicates that our model predicted a red and it actually also was a red 626 times.\n",
    "\n",
    "In the other cases it was wrong (311 times predicted red, but was blue, and 18 times predicted blue and was red).\n",
    "\n",
    "To double-check the math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(19+626)/(19+311+18+626)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same 66% as we saw earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it did try its best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussNB.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3. Only binary outcomes?\n",
    "What if our outcome variable is not two, but three or more categories?\n",
    "\n",
    "Well lets see what happens if we don't remove the draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original data\n",
    "mDat = UFCnum[[\"B_age\", \"R_age\", \"Winner\"]]\n",
    "winTypes ={\"Red\":0, \"Blue\":1, \"Draw\":2} \n",
    "\n",
    "# Convert 'Winner' to numerical values as a list\n",
    "numWin = [winTypes[i] for i in mDat[\"Winner\"]]  \n",
    "numWin = pd.DataFrame(numWin)\n",
    "\n",
    "# Combine the two data frames\n",
    "mDat = pd.concat([mDat,numWin], axis=1, sort=False)\n",
    "\n",
    "# Remove the original 'Winner'\n",
    "mDat = mDat.drop([\"Winner\"], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "mDat.columns = [\"B_age\", \"R_age\", \"Winner\"]\n",
    "\n",
    "#Remove the missing values\n",
    "mDat=mDat.dropna()\n",
    "\n",
    "# Now get X and Y:\n",
    "X = mDat[[\"B_age\", \"R_age\"]]\n",
    "y = mDat[\"Winner\"]\n",
    "\n",
    "# And convert them to a numpy array\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109)\n",
    "\n",
    "#Create the model and prediction\n",
    "gaussNB.fit(X_train, y_train)\n",
    "y_pred = gaussNB.predict(X_test)\n",
    "\n",
    "# Finally the result:\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there doesn't seem to be any problem. \n",
    "\n",
    "It did not predict any draws, but we only have 19 draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**\n",
    "\n",
    "Improve the model by adding some other variables you think might be useful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4. Other similar techniques\n",
    "We discussed the basic ideas and concepts of the Naive Bayes method for classification. There is also \n",
    "\n",
    "* Multinomial Naive Bayes <br>\n",
    "Helpful if your numerical values are counts.\n",
    "* Complement Naive Bayes <br>\n",
    "an extension of Multinomial Naive Bayes and used if the dataset is imbalanced.\n",
    "* Bernoulli Naive Bayes <br>\n",
    "if you have binary/boolean features.\n",
    "* Average One-Dependence Estimators (AODE), which is a bit out of scope from this course.\n",
    "\n",
    "Before we finish this chapter. Lets take a quick peek at our original data and the winners (should we have done this when we started?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UFCdata[\"Winner\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm. Only 83 draws and Red seems to win most of the time. Is there a reason why this might happen? We would need an expert on MMA to find this out. Perhaps if we see Micha he can explain. \n",
    "\n",
    "Alright, perhaps another technique can improve our performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>BACK TO THE SLIDES</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn has a nice Python script themselves to be used as an example (https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html) and also on https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html some very nice explanations are given. So lets not re-invent the wheel, and I've used some of their bits.\n",
    "\n",
    "Beginning with creating some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y = make_blobs(n_samples=50, centers=2,\n",
    "                  random_state=18, cluster_std=1.60)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to create our Support Vector Machine (or Support Vector Classifier). \n",
    "\n",
    "We first use the linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required SVC package from sklearn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the model, then fit the model, and determine the predicted values\n",
    "svmLin = SVC(kernel='linear')\n",
    "svmLin.fit(X, y)\n",
    "y_pred = svmLin.predict(X)\n",
    "\n",
    "# Finally the result:\n",
    "print(metrics.accuracy_score(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show the result, using the small function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHyperplane(X, y, model):\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "    # plot the decision function\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # create grid to evaluate model\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = svmLin.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    # plot support vectors\n",
    "    ax.scatter(svmLin.support_vectors_[:, 0], svmLin.support_vectors_[:, 1], s=100,\n",
    "               linewidth=1, facecolors='none', edgecolors='k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showHyperplane(X, y, svmLin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other example on the slides was the circular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "X, y = make_circles(100, factor=.1, noise=.1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, oh. Doesn't look promising to draw a straight line to separate the red from yellow dots. Lets see how well sklearn can do this anyway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmLin = SVC(kernel='linear').fit(X, y)\n",
    "svmLin.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, still 69% correct. What would this look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showHyperplane(X,y,svmLin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, its something but by observation alone we can see that the hyperplane should not be a straight line anymore, but a circle is much more obvious.\n",
    "\n",
    "Translate our scores to circle-style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=X[:,0]**2+X[:,1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize using ipywidgets, so make sure you have installed it (using pip install ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "\n",
    "def plot_3D(elev=30, azim=30, X=X, y=y):\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter3D(X[:, 0], X[:, 1], Z, c=y, s=50, cmap='autumn')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('Z')\n",
    "\n",
    "interact(plot_3D, elev=[20, 70], azip=(-180, 180),\n",
    "         X=fixed(X), y=fixed(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the plane that separates these points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmRBF = SVC(kernel='rbf').fit(X, y)\n",
    "y_pred = svmRBF.predict(X)\n",
    "\n",
    "# The result:\n",
    "print(metrics.accuracy_score(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. This separates all our points correctly (we should of course use some test and training data, but you get the point)\n",
    "\n",
    "Lets apply this to our UFC data. First just in case select the data again, and split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a subset of the data and remove missing values\n",
    "UFCsel = UFCdata[[\"Winner\", \"B_age\", \"R_age\"]]\n",
    "UFCsel=UFCsel.dropna()\n",
    "\n",
    "#Determine input and output variables\n",
    "X = UFCsel[[\"B_age\", \"R_age\"]]\n",
    "y = UFCsel[\"Winner\"]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to create the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVM with linear kernel\n",
    "svmLin = SVC(kernel='linear')\n",
    "svmLin.fit(X_train, y_train)\n",
    "y_pred = svmLin.predict(X_test)\n",
    "\n",
    "print('SVM Linear Kernel results')\n",
    "print('accuracy score: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('')\n",
    "\n",
    "# SVM with Radial Basis Function kernel\n",
    "rbfKer = SVC(kernel='rbf')\n",
    "rbfKer.fit(X_train, y_train)\n",
    "y_pred = rbfKer.predict(X_test)\n",
    "\n",
    "print('SVM RBF Kernel results')\n",
    "print('accuracy score: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There some other kernels as well available in sklearn. Unfortunately not enough time to explain all of them, but just FYI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one takes a long time, so commented it out\n",
    "\n",
    "## SVM with Polynomial kernel\n",
    "#svmPol = SVC(kernel='poly')\n",
    "#svmPol.fit(X_train, y_train)\n",
    "#y_pred = svmPol.predict(X_test)\n",
    "\n",
    "#print('accuracy score: ',metrics.accuracy_score(y_test, y_pred))\n",
    "#print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#Result was 0.6636363636..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with Sigmoid Kernel\n",
    "svmSigm = SVC(kernel='sigmoid')\n",
    "svmSigm.fit(X_train, y_train)\n",
    "y_pred = svmSigm.predict(X_test)\n",
    "\n",
    "print('accuracy score: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to definately check is how many support vectors we actually have. If this is too high we might be overfitting the data. Usually at 10% or more you should get a bit worried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear kernel percentage: ',len(svmLin.support_)/len(X_train))\n",
    "print('RBF kernel percentage: ',len(svmRBF.support_)/len(X_train))\n",
    "#print('Polynomial kernel percentage: ',len(polKer.support_)/len(X_train))\n",
    "print('Sigmoid kernel percentage: ',len(svmSigm.support_)/len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ai, thats more than 65% of our test data points are used to create the hyperplane itself, except for the RBF kernel. So at this moment I'd go for that one.\n",
    "\n",
    "For the other kernels we might need to soften our margin (the C parameter). \n",
    "\n",
    "But lets see how another technique might actually perform..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>BACK TO THE SLIDES</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. KNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the slides the basic idea of kNN was discussed. Implementing this with sklearn is very similar as we've seen before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the KNeighborsClassifier package\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Setup and fit the model (we use the same data as before)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create the prediction\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "# Show the results\n",
    "print('accuracy score: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost a must in KNN classification is to set the data to a standard scale. This is accomplished by subtracting the mean from each value, and then divide the result by the standard deviation. These are also known as Z-scores. In formula notation:\n",
    "\n",
    "\\begin{equation*}\n",
    "Z = \\frac{x - \\bar{x}}{\\sigma}\n",
    "\\end{equation*}\n",
    "\n",
    "The $\\bar{x}$ is the mean of field X, and $\\sigma$ is the population standard deviation (the sample standard deviation to be a bit more precise)\n",
    "\n",
    "We could of course easily do this ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zscores = (X_train - X_train.mean())/X_train.std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course, sklearn has us covered..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the standardscaler package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# set the scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Convert the train and test X values, using the same scaler (so based on the X_train)\n",
    "X_trainScaled = scaler.transform(X_train)\n",
    "X_testScaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check if they are indeed the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainScaled - Zscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if this pays off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_trainScaled, y_train)\n",
    "y_pred=knn.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed a bit, but not much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One suggestion for the setting of k (the number of neighbors to consider) is to take the square root of the number of data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0]**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An odd number is usually preferred (to avoid ties), so lets use 63 and see if that helps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=63)\n",
    "\n",
    "knn.fit(X_trainScaled, y_train)\n",
    "y_pred=knn.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about 3% better. We can also just iterate over a range and look which performs best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks for the script: https://datascienceplus.com/k-nearest-neighbors-knn-with-python/\n",
    "error_rate=[]\n",
    "for i in range(1,80):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_trainScaled, y_train)\n",
    "    pred_i = knn.predict(X_testScaled)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,80),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 43 things go slightly up again and not much differences anymore after that. Lets check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=43)\n",
    "\n",
    "knn.fit(X_trainScaled, y_train)\n",
    "y_pred=knn.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, only another 1% increase in our performance, but less computational than the k=63\n",
    "\n",
    "Another approach could be to use the so called 'GridSearchCV' package, which will iterate over a lot of settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was copied from https://medium.com/datadriveninvestor/k-nearest-neighbors-in-python-hyperparameters-tuning-716734bc557f\n",
    "\n",
    "I've commented out the code since it takes a very long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List Hyperparameters that we want to tune.\n",
    "#leaf_size = list(range(1,50))\n",
    "#n_neighbors = list(range(1,30))\n",
    "#p=[1,2]\n",
    "##Convert to dictionary\n",
    "#hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "##Create new KNN object\n",
    "#knn_2 = KNeighborsClassifier()\n",
    "##Use GridSearch\n",
    "#clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "##Fit the model\n",
    "#best_model = clf.fit(X_trainScaled, y_train)\n",
    "##Print The value of best Hyperparameters\n",
    "#print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "#print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "#print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "\n",
    "# The result was a leaf size of 1, p of 1 and 29 neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnOptimal = KNeighborsClassifier(n_neighbors=29, leaf_size=1, p=1)\n",
    "y_pred=knn.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar result, but a lot lower number of neighbors.\n",
    "\n",
    "Our model never seems to predict a 'Draw'. One possible reason might be that we are looking at the 29 neighbors of a point, and we only have 17 draws in total. The chances that a draw will win a majority vote is very low.\n",
    "\n",
    "If you find the confusion matrix, well confusing. You might also use the classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll leave it up to you to google on how to interpret this, since we still have a lot to discuss. There are so many more techniques.\n",
    "\n",
    "The optimal settings from GridSearch set something called 'leafs'. To understand this better it can help to look at our next technique: Decision Trees....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>BACK TO THE SLIDES</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of Decision trees is explained on the slide. The simplest version requires another package, so **first run 'pip install decision-tree-id3' in shell**, then come back here to actually load the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install decision-tree-id3\n",
    "\n",
    "# importing it directly seems to have a small bug, so\n",
    "# first import six and sys\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "# then finally id3\n",
    "from id3 import Id3Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_dtc=Id3Estimator()\n",
    "id3_dtc.fit(X_trainScaled,y_train)\n",
    "y_pred = id3_dtc.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad.\n",
    "\n",
    "sklearn also has a 'DecisionTreeClassifier' and we can set the criterion for that to 'entropy':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "ent_dtc = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "ent_dtc.fit(X_trainScaled,y_train)\n",
    "y_pred = ent_dtc.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. The documentation of DecisionTreeClassifier mentions: \"...“entropy” for the information gain.\", so this should be the same as the id3. It could be that either there is a small variation in the id3 method, or sklearn uses different default settings than id3. Something to look into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn does not have a pure C4.5 implementation, but usually CART is enough. We can get this by either not setting a criterion (since it's the default), or set it to 'gini':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_dtc = DecisionTreeClassifier(criterion = \"gini\")\n",
    "gini_dtc.fit(X_trainScaled,y_train)\n",
    "y_pred = gini_dtc.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier is also available in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "rfcModel = rfc.fit(X_trainScaled, y_train)\n",
    "y_pred = rfcModel.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just because its there, a quick show of the Extra Trees classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Extremly Random Forest (a.k.a. Extra trees)\n",
    "erfc = ExtraTreesClassifier(random_state=0)\n",
    "erfc = erfc.fit(X_trainScaled, y_train)\n",
    "y_pred = erfc.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest and Extra Trees seem to outperform the best decision tree. Actually Random Forest and Extra Trees are not really a decision tree, but more a decision tree**s**. This is because it is a bagging (bootstrap aggregation) technique. What's that you ask? Well...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>BACK TO THE SLIDES</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. And Many More"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section just some basic code showing a few more methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "ldaModel=lda.fit(X_trainScaled, y_train)\n",
    "y_pred=ldaModel.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quadratic Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qdaModel=qda.fit(X_trainScaled, y_train)\n",
    "y_pred=ldaModel.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "lrModel = logreg.fit(X_trainScaled, y_train)\n",
    "y_pred = lrModel.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial Logistic Regression Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(multi_class='multinomial')\n",
    "lrModel = logreg.fit(X_trainScaled, y_train)\n",
    "y_pred = lrModel.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoos**\n",
    "(Adaptive Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaBst = AdaBoostClassifier(random_state=0)\n",
    "adaBst = adaBst.fit(X_trainScaled, y_train)\n",
    "y_pred = adaBst.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gradBst = GradientBoostingClassifier(random_state=0)\n",
    "gradBst = gradBst.fit(X_trainScaled, y_train)\n",
    "y_pred = gradBst.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "histBst = HistGradientBoostingClassifier(random_state=0)\n",
    "histBst = histBst.fit(X_trainScaled, y_train)\n",
    "y_pred = histBst.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('svr', make_pipeline(StandardScaler(),\n",
    "                          LinearSVC(random_state=42)))]\n",
    "\n",
    "stackCl = StackingClassifier(estimators=estimators, final_estimator = LogisticRegression())\n",
    "stackCl.fit(X_trainScaled, y_train)\n",
    "y_pred = stackCl.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Classifier - Most Frequent** <br>\n",
    "Sometimes referred to as ZeroR classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dumMF = DummyClassifier(strategy='most_frequent')\n",
    "dumMF = dumMF.fit(X_trainScaled, y_train)\n",
    "y_pred = dumMF.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Classifier - Stratified**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy classifier with stratified method\n",
    "dumSrat = DummyClassifier(strategy=\"stratified\")\n",
    "dumSrat = dumSrat.fit(X_trainScaled, y_train)\n",
    "y_pred = dumSrat.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Classifier - Prior**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumPrior = DummyClassifier(strategy=\"prior\")\n",
    "dumPrior.fit(X_trainScaled, y_train)\n",
    "y_pred = dumPrior.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Clasifier - Uniform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumUni = DummyClassifier(strategy=\"uniform\")\n",
    "dumUni.fit(X_trainScaled, y_train)\n",
    "y_pred = dumUni.predict(X_testScaled)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>BACK TO THE SLIDES</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all these different models, I was a bit curious to just list all of them in one go. So..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a panda dataframe to keep track of the scores\n",
    "accScores = pd.DataFrame(columns = ['model', 'score'])\n",
    "\n",
    "# Create a list with all the different models (except polynomial svm).\n",
    "models =[[\"Dummy - Uniform\", DummyClassifier(strategy=\"uniform\")]]\n",
    "models.append(['Dummy - Most Freq.', DummyClassifier(strategy=\"stratified\")])\n",
    "models.append(['Dummy - Prior', DummyClassifier(strategy=\"prior\")])\n",
    "models.append(['Dummy - Most Freq.', DummyClassifier(strategy='most_frequent')])\n",
    "models.append(['NB - Gaussian', GaussianNB()])\n",
    "models.append(['SVM - Gaussian', SVC(kernel='linear')])\n",
    "models.append(['SVM - RBF', SVC(kernel='rbf')])\n",
    "models.append(['SVM - Sigmoid', SVC(kernel='sigmoid')])\n",
    "models.append(['kNN', KNeighborsClassifier(n_neighbors=29, leaf_size=1, p=1)])\n",
    "models.append(['DT - ID3', Id3Estimator()])\n",
    "models.append(['DT - ID3 (sklearn)', DecisionTreeClassifier(criterion = \"entropy\")])\n",
    "models.append(['DT - CART', DecisionTreeClassifier(criterion = \"gini\")])\n",
    "models.append(['Bagging - Random Forest', RandomForestClassifier(random_state=0)])\n",
    "models.append(['Bagging - Extra Trees', ExtraTreesClassifier(random_state=0)])\n",
    "models.append(['LDA', LinearDiscriminantAnalysis()])\n",
    "models.append(['QDA', QuadraticDiscriminantAnalysis()])\n",
    "models.append(['Logistic Regression', LogisticRegression()])\n",
    "models.append(['Multinomial LR', LogisticRegression(multi_class='multinomial')])\n",
    "models.append(['Boosting - AdaBoost', AdaBoostClassifier(random_state=0)])\n",
    "models.append(['Boosting - Gradient', GradientBoostingClassifier(random_state=0)])\n",
    "models.append(['Boosting - Histogram Gradient', HistGradientBoostingClassifier(random_state=0)])\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('svr', make_pipeline(StandardScaler(),\n",
    "                          LinearSVC(random_state=42)))]\n",
    "models.append(['Stacking', StackingClassifier(estimators=estimators, final_estimator = LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to iterate over all of them:\n",
    "for i in models:\n",
    "    model = i[1]\n",
    "    model.fit(X_trainScaled, y_train)\n",
    "    y_pred = model.predict(X_testScaled)\n",
    "    score=metrics.accuracy_score(y_test, y_pred)\n",
    "    newRow=pd.Series([i[0], score], index=accScores.columns)\n",
    "    accScores=accScores.append(newRow, ignore_index=True)\n",
    "    \n",
    "# And show all results sorted by their score:\n",
    "accScores.sort_values(by=['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also XGboost, but that requires numerical data. If you are interested check out https://machinelearningmastery.com/data-preparation-gradient-boosting-xgboost-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
